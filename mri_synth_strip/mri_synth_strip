#!/usr/bin/env python

import os
import numpy as np
import freesurfer as fs
import warnings


desc = '''
This program strips skull and other outer non-brain tissue from
an image. The conservativeness of the masking can be fine-tuned
using the --border flag.
'''

# parse commandline args
parser = fs.utils.ArgumentParser(description=desc)
parser.add_argument('-i', '--input', required=True, help='Input image filename.')
parser.add_argument('-o', '--output', required=True, help='Masked output image filename.')
parser.add_argument('-m', '--mask', help='Output mask filename.')
parser.add_argument('-b', '--border', default=1, type=int, help='Mask border threshold. Default is 1.')
parser.add_argument('--model', help='Alternative model file.')
parser.add_argument('-v', '--verbose', action='store_true', help='Verbose output for debugging.')
parser.add_argument('-g', '--gpu', help='GPU ID. CPU is used by default.')
parser.add_argument('--max-norm', action='store_true', help='Normalize by max intensity instead of 97th percentile.')
args = parser.parse_args()

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0' if args.verbose else '3'

# defer slow tensorflow imports for faster argument parsing
import neurite as ne
import voxelmorph as vxm
import tensorflow as tf
import tensorflow.keras.layers as KL

# set verbosity
if not args.verbose:
    warnings.filterwarnings('ignore')
    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# configure model file
if args.model is not None:
    model_file = args.model
else:
    fshome = fs.fshome()
    if fshome is None:
        fs.fatal('FREESURFER_HOME must be configured to find model files.')
    model_file = os.path.join(fshome, 'models', 'synthstrip.dtrans.h5')

# configure Strip model
# TODO: needs to be moved to neurite
class Strip(ne.tf.modelio.LoadableModel):
    """
    SynthStrip model for learning subject-to-subject registration from images
    with arbitrary contrasts synthesized from label maps.
    """
    @ne.tf.modelio.store_config_args
    def __init__(self,
                 inshape,
                 nb_unet_features=None,
                 nb_unet_levels=None,
                 unet_feat_mult=1,
                 nb_unet_conv_per_level=1,
                 src_feats=1,
                 segout=False):
        ndims = len(inshape)
        assert ndims in [1, 2, 3], 'ndims should be one of 1, 2, or 3. found: %d' % ndims
        unet = vxm.networks.Unet(
                 inshape=(*inshape, src_feats),
                 nb_features=nb_unet_features,
                 nb_levels=nb_unet_levels,
                 feat_mult=unet_feat_mult,
                 nb_conv_per_level=nb_unet_conv_per_level,
                 name='strip_unet')
        conv = getattr(KL, 'Conv%dD' % ndims)
        if segout:
            prob = conv(2, kernel_size=3, padding='same', name='seg_prob')(unet.output)
            prob = tf.keras.layers.Softmax()(prob)
        else:
            prob = conv(1, kernel_size=3, padding='same', name='strip_prob')(unet.output)
        super().__init__(inputs=unet.input, outputs=prob)

class SynthStripTrainer(ne.tf.modelio.LoadableModel):
    """
    SynthStrip model for learning subject-to-subject registration from images
    with arbitrary contrasts synthesized from label maps.
    """
    @ne.tf.modelio.store_config_args
    def __init__(self,
                 inshape,
                 labels_in,
                 labels_out,
                 old_synth=False,
                 synth_params={},
                 **kwargs):
        inshape = tuple(inshape)
        image = KL.Input(inshape)
        strip_model = Strip(inshape, **kwargs)
        prob = strip_model(image)
        super().__init__(inputs=image, outputs=prob)

# load model 
device, ngpus = ne.tf.utils.setup_device(args.gpu)
with tf.device(device):
    model = SynthStripTrainer.load(model_file)

# load input volume
in_img = fs.Volume.read(args.input)

# conform image and normalize
conf_img = in_img.conform(shape=(256, 256, 256), voxsize=1.0, dtype='float32', interp_method='nearest')
in_data = conf_img.data
in_data -= in_data.min()
if args.max_norm:
    in_data /= in_data.max()
else:
    in_data = np.clip(in_data / np.percentile(in_data, 99), 0, 1)

# load model and predict
with tf.device(device):
    pred = model.predict(in_data[np.newaxis, ..., np.newaxis]).squeeze()

# unconform the predicted mask
mask = conf_img.copy(pred).resample_like(in_img)

# save mask
if args.mask:
    mask.write(args.mask)

# mask the input image
masked_img = in_img.copy()
masked_img.data[mask.data.squeeze() >= args.border] = 0
masked_img.write(args.output)
