#!/usr/bin/env python3

import os
import numpy as np
import nibabel as nib
import argparse
import freesurfer as fs

from freesurfer import samseg

eps = np.finfo(float).eps

#parser = fs.utils.ArgumentParser()
#parser.add_argument('--subjects-dir', metavar='DIR', help='Directory with saved SAMSEG runs with --history flag.', required=True)
#parser.add_argument('--mesh-collections', nargs='+', metavar='FILE', help='Mesh collection file(s).', required=True)
#parser.add_argument('--out-dir', help='Output directory.', required=True)
#parser.add_argument('--showfigs', action='store_true', default=False, help='Show figures during run.')
#args = parser.parse_args()


subjects_dir = '/home/paul/lcn/20210426-ds001420-samseg-recon/fs-sub'
# This needs to be the same atla used when running the dataset
mesh_collections = ['/opt/freesurfer-20210513-fs-infant-dev-merge/average/samseg/20Subjects_smoothing2_down2_smoothingForAffine2/atlas_level1.txt.gz', '/opt/freesurfer-20210513-fs-infant-dev-merge/average/samseg/20Subjects_smoothing2_down2_smoothingForAffine2/atlas_level2.txt.gz']
out_dir = '/tmp/out'
showfigs = False

# After running a dataset through samseg with `--save-posteriors`, find a list of 
# valid lables using:
#   `ls -1 $SUBJECTS_DIR/$SUB/mri/samseg/posteriors |sed 's/.mgz//'
# From Doug: For the cortex project, we'll need at least cortex (lh and rh) and wm (lh and rh), and maybe lateral ventricles (lh and rh).
label_set = ['Left-Cerebral-Cortex', 'Left-Cerebral-White-Matter', 'Left-Lateral-Ventricle', 'Right-Cerebral-Cortex', 'Right-Cerebral-White-Matter', 'Right-Lateral-Ventricle']

numberOfLabels = len(label_set)

if not os.path.exists(out_dir):
    os.makedirs(out_dir)

if showfigs:
    visualizer = samseg.initVisualizer(True, True)
else:
    visualizer = samseg.initVisualizer(False, False)

# We need an init of the probabilistic segmentation class
# to call instance methods
atlas = samseg.ProbabilisticAtlas()

subjectList = [ pathname for pathname in os.listdir(subjects_dir) \
                  if os.path.isdir(os.path.join(subjects_dir, pathname)) ]
numberOfSubjects = len(subjectList)

for level, meshCollectionFile in enumerate(mesh_collections):
    ## DEBUG
    if level > 1: break
    
    print("Working on mesh collection at level " + str(level + 1))

    # Read mesh collection
    print("Loading mesh collection at: " + str(meshCollectionFile))
    meshCollection = samseg.gems.KvlMeshCollection()
    meshCollection.read(meshCollectionFile)

    # We are interested only on the reference mesh
    mesh = meshCollection.reference_mesh
    numberOfNodes = mesh.point_count

    print('Number of subjects: ' + str(len(subjectList)))

    # Define what we are interesting in, i.e., the label statistics of lesion
    labelStatisticsInMeshNodes = np.zeros([numberOfNodes, numberOfLabels, numberOfSubjects])

    for subjectNumber, subjectDir in enumerate(subjectList):
        print('Working on Subject:', subjectDir)
        # Load the history file and model params
        history_filename = os.path.join(subjects_dir, subjectDir, 'mri/samseg/history.p')
        history = np.load(history_filename, allow_pickle=True)
        modelSpecifications = history['input']['modelSpecifications']
        transform_matrix = history['transform']
        transform = samseg.gems.KvlTransform(samseg.requireNumpyArray(transform_matrix))
        deformations = history['historyWithinEachMultiResolutionLevel'][level]['deformation']
        deformationAtlasFileName = history['historyWithinEachMultiResolutionLevel'][level]['deformationAtlasFileName']
        cropping = history['cropping']
                
        for label_num, label_name in enumerate(label_set):
            print('Loading labal:', label_name)
            posterior_filename = os.path.join(subjects_dir, subjectDir, 'mri/samseg/posteriors', label_name+'.mgz')
            probImage = nib.load(posterior_filename).get_fdata()                      
            nodePositions = atlas.getMesh(
              meshCollectionFile,
              transform,
              K=modelSpecifications.K,
              initialDeformation=deformations,
              initialDeformationMeshCollectionFileName=meshCollectionFile
            ).points
            # init np array
            if label_num == 0:
                subject_posteriorMap_float = np.zeros([probImage.shape[0], probImage.shape[1], probImage.shape[2], numberOfLabels], np.float)
            
            subject_posteriorMap_float[:,:,:,label_num] = probImage
            # The image is cropped as well so the voxel coordinates
            # do not exactly match with the original image,
            # i.e., there's a shift. Let's undo that.            
            nodePositions += [slc.start for slc in cropping]

        # subject_posteriorMap_float is now fully loaded, noramlize so it sums to 1 across the label dimension
        # TODO
    
        # Estimate alphas representing the new posterior map, initialized with a flat prior
        subject_posteriorMap_uint16 = np.uint16(subject_posteriorMap_float * 65535)
        alphas = np.zeros([numberOfNodes, 2]) + 0.5
        mesh = meshCollection.reference_mesh
        mesh.points = nodePositions
        mesh.alphas = mesh.fit_alphas(subject_posteriorMap_uint16)

        # Show rasterized prior with updated alphas
        if showfigs:
            rasterizedPrior = mesh.rasterize(segmentationImage.shape, 1) / 65535
            visualizer.show(images=rasterizedPrior)

        # Show progress to anyone who's watching
        print('====================================================================')
        print('')
        print('subjectNumber: ' + str(subjectNumber + 1))
        print('')
        print('====================================================================')

        # Save label statistics of subject
        labelStatisticsInMeshNodes[:, :, subjectNumber] = mesh.alphas.copy()

    # Save label statistics in a npy file
    np.save(os.path.join(out_dir, 'labelStatistics_atlas_%d' % level), labelStatisticsInMeshNodes)
